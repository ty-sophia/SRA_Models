{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145ce562",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d80c7",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60991d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "import argparse\n",
    "\n",
    "#Numerical Manipulation\n",
    "import random\n",
    "import array\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#tools\n",
    "import shutil #file processing\n",
    "from glob import glob #find pathnames\n",
    "import itertools\n",
    "import gc #garbage collector\n",
    "import json #notation\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import class_weight as cw\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Machine Learning Evaluation\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Deep Learning - Keras -  Preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Deep Learning - Keras - Model\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Deep Learning - Keras - Layers\n",
    "from keras.layers import Convolution1D, concatenate, SpatialDropout1D, GlobalMaxPool1D, GlobalAvgPool1D, Embedding, \\\n",
    "    Conv2D, SeparableConv1D, Add, BatchNormalization, Activation, GlobalAveragePooling2D, LeakyReLU, Flatten\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, \\\n",
    "    Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n",
    "#from keras.layers.pooling import _GlobalPooling1D\n",
    "\n",
    "# Deep Learning - Keras - Pretrained Model \n",
    "from keras.applications.xception import Xception\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "from tensorflow.keras.applications.nasnet import NASNetMobile, NASNetLarge\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input\n",
    "\n",
    "# Deep Learning - Keras - Evaluation\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD , RMSprop\n",
    "from tensorflow.keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n",
    "\n",
    "# Deep Learning - Keras - Visualization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "\n",
    "# Deep Learning - TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Graphing/ Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "#from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# Image\n",
    "#import cv2\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "#from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c46b46",
   "metadata": {},
   "source": [
    "# 1. Set I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debddf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sophiaty/Desktop/SRA Codes/Subset 1 - Binary Classification/input/train\n",
      "/Users/sophiaty/Desktop/SRA Codes/Subset 1 - Binary Classification/input/test\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "import argparse\n",
    "\n",
    "#input folders\n",
    "cur_dir = os.getcwd()\n",
    "train_dir = cur_dir + r\"/input/train\"\n",
    "test_dir = cur_dir + r\"/input/test\"\n",
    "Subfolder_numbers = 7\n",
    "\n",
    "print (train_dir)\n",
    "print (test_dir)\n",
    "\n",
    "#output folders\n",
    "output_dir = '/Users/sophiaty/Desktop/SRA Codes/Subset 1 - Binary Classification/output/'\n",
    "figure_dir = '/Users/sophiaty/Desktop/SRA Codes/Subset 1 - Binary Classification/output/figures'\n",
    "\n",
    "#Check output folders\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "if not os.path.exists(figure_dir):\n",
    "    os.mkdir(figure_dir)\n",
    "    \n",
    "#prepare files\n",
    "fname_predict_batch = figure_dir+r\"/result\"\n",
    "fname_predict_sample = figure_dir+r\"/sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011060fb",
   "metadata": {},
   "source": [
    "# 2. Get filenames and parse strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d018a14",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c2c9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to parse files\n",
    "def data_parser(image_dir, X, i, FNAME, TISSUE, T_CLASS, Subfolder_numbers):\n",
    "    basepath = Path(image_dir)\n",
    "    files_in_basepath = basepath.iterdir()\n",
    "    for item in files_in_basepath:\n",
    "        i = i+1\n",
    "        if item.is_file():\n",
    "            X = os.path.splitext(item)\n",
    "            strng = X[0]\n",
    "            cut = strng.split('/') #remove input and test/train directory\n",
    "            fname = cut[Subfolder_numbers + 1] #get filename\n",
    "            if \".DS\" not in fname:\n",
    "                FNAME.append(fname)\n",
    "                tissue = fname.split('_')\n",
    "                if \"HF\" in tissue[0] or \"hF\" in tissue[0] or \"hf\" in tissue[0] or \"Hf\" in tissue[0]:\n",
    "                        TISSUE.append('HF')\n",
    "                        T_CLASS.append(1)\n",
    "                else:\n",
    "                    TISSUE.append(tissue[0])\n",
    "                    T_CLASS.append(0)\n",
    "            else:\n",
    "                continue\n",
    "            i = i+1 \n",
    "\n",
    "    FNAME = np.array(FNAME)\n",
    "    TISSUE = np.array(TISSUE)\n",
    "    T_CLASS = np.array(T_CLASS)\n",
    "    print(len(FNAME))\n",
    "    \n",
    "    return(FNAME, TISSUE, T_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b56366",
   "metadata": {},
   "source": [
    "## Call Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc16153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import array\n",
    "\n",
    "image_dir = r'all images'\n",
    "X = [] #splicer\n",
    "i = 0 #iterator\n",
    "\n",
    "#Training Headers\n",
    "train_FNAME = []\n",
    "train_TISSUE = []\n",
    "train_CLASS = []\n",
    "\n",
    "train_arrays = data_parser(train_dir, X, i, train_FNAME, train_TISSUE, train_CLASS, Subfolder_numbers)\n",
    "\n",
    "#Testing Headers\n",
    "test_FNAME = []\n",
    "test_TISSUE = []\n",
    "test_CLASS = []\n",
    "\n",
    "test_arrays = data_parser(test_dir, X, i, test_FNAME, test_TISSUE, test_CLASS, Subfolder_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626cdc8",
   "metadata": {},
   "source": [
    "# 3. Create CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89695f4",
   "metadata": {},
   "source": [
    "## Training Set Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e6447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library\n",
    "import csv\n",
    "\n",
    "with open ('train_labels.csv', mode = 'w') as csv_file:\n",
    "    fieldnames = ['Filename', 'Tissues', 'Binary Class']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "for i in range (len(train_FNAME)):\n",
    "    with open('train_labels.csv', mode='a') as csv_file:\n",
    "        fieldnames = ['Filename', 'Tissues', 'Binary Class']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writerow({ 'Filename': train_FNAME[i], 'Tissues': train_TISSUE[i], 'Binary Class' : train_CLASS[i]})\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e611a45",
   "metadata": {},
   "source": [
    "## Testing Set Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe467a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('test_labels.csv', mode = \"w\") as test_file:\n",
    "    fieldnames = ['Filename', 'Tissues', 'Binary Class']\n",
    "    writer = csv.DictWriter(test_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "for i in range (len(test_FNAME)):\n",
    "    with open ('test_labels.csv', mode = 'a') as test_file:\n",
    "        fieldnames = ['Filename', 'Tissues', 'Binary Class']\n",
    "        writer = csv.DictWriter(test_file, fieldnames=fieldnames)\n",
    "        writer.writerow({ 'Filename': test_FNAME[i], 'Tissues': test_TISSUE[i], 'Binary Class' : test_CLASS[i]})\n",
    "\n",
    "test_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f0005",
   "metadata": {},
   "source": [
    "# 4. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f2803",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e16f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Tissues</th>\n",
       "      <th>Binary Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCC_14 copy.png</td>\n",
       "      <td>BCC</td>\n",
       "      <td>Non HF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCC_15 copy.png</td>\n",
       "      <td>BCC</td>\n",
       "      <td>Non HF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HF_09 copy.png</td>\n",
       "      <td>HF</td>\n",
       "      <td>HF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCC_20 copy.png</td>\n",
       "      <td>BCC</td>\n",
       "      <td>Non HF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCC_21 copy.png</td>\n",
       "      <td>BCC</td>\n",
       "      <td>Non HF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Filename Tissues Binary Class\n",
       "0  BCC_14 copy.png     BCC       Non HF\n",
       "1  BCC_15 copy.png     BCC       Non HF\n",
       "2   HF_09 copy.png      HF           HF\n",
       "3  BCC_20 copy.png     BCC       Non HF\n",
       "4  BCC_21 copy.png     BCC       Non HF"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "m = {0:'Non HF', 1:'HF'}\n",
    "target_dir = os.getcwd()\n",
    "\n",
    "train_df = pd.read_csv(target_dir+\"/train_labels.csv\")\n",
    "train_df['Filename'] = train_df['Filename'].apply(lambda x:x+\".png\")\n",
    "train_df['Binary Class'] = train_df['Binary Class'].map(m)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2eb48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Tissues</th>\n",
       "      <th>Binary Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HF_36 copy.png</td>\n",
       "      <td>HF</td>\n",
       "      <td>HF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCC_37 copy.png</td>\n",
       "      <td>BCC</td>\n",
       "      <td>Non HF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCC_36 copy.png</td>\n",
       "      <td>BCC</td>\n",
       "      <td>Non HF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCC_40 copy.png</td>\n",
       "      <td>BCC</td>\n",
       "      <td>Non HF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCC_41 copy.png</td>\n",
       "      <td>BCC</td>\n",
       "      <td>Non HF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Filename Tissues Binary Class\n",
       "0   HF_36 copy.png      HF           HF\n",
       "1  BCC_37 copy.png     BCC       Non HF\n",
       "2  BCC_36 copy.png     BCC       Non HF\n",
       "3  BCC_40 copy.png     BCC       Non HF\n",
       "4  BCC_41 copy.png     BCC       Non HF"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(target_dir+\"/test_labels.csv\")\n",
    "test_df['Filename'] = test_df['Filename'].apply(lambda x:x+\".png\")\n",
    "test_df['Binary Class'] = test_df['Binary Class'].map(m)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a10a9",
   "metadata": {},
   "source": [
    "## Pretraining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e63f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this performs data augmentation built in keras\n",
    "#this also changes the weights\n",
    "def get_data(batch_size=32, target_size=(299, 299), class_mode=\"categorical\", training_dir=train_dir, testing_dir=test_dir):\n",
    "    print(\"Generating data following preprocessing...\\n\")\n",
    "    \n",
    "    rescale = 1.0/255\n",
    "\n",
    "    train_batch_size = batch_size\n",
    "    test_batch_size = batch_size\n",
    "    \n",
    "    train_shuffle = True\n",
    "    val_shuffle = True\n",
    "    test_shuffle = False\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=45,\n",
    "        shear_range=16,\n",
    "        rescale=rescale,\n",
    "        validation_split=0.25)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df, \n",
    "        training_dir,\n",
    "        x_col='Filename',\n",
    "        y_col='Binary Class',\n",
    "        target_size=target_size, \n",
    "        class_mode=class_mode, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        seed=42,\n",
    "        subset='training')\n",
    "    \n",
    "    validation_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df, \n",
    "        training_dir,\n",
    "        x_col='Filename',\n",
    "        y_col='Binary Class',  \n",
    "        target_size=target_size, \n",
    "        class_mode=class_mode, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        seed=42,\n",
    "        subset='validation')\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        test_df, \n",
    "        testing_dir,\n",
    "        x_col='Filename',\n",
    "        y_col='Binary Class',\n",
    "        target_size=target_size, \n",
    "        class_mode=class_mode, \n",
    "        batch_size=1024, \n",
    "        shuffle=False, \n",
    "        seed=42)\n",
    "    \n",
    "    #this modifies the training set\n",
    "    class_weights = get_weight(train_generator.classes)\n",
    "    \n",
    "    steps_per_epoch = len(train_generator)\n",
    "    validation_steps = len(validation_generator)\n",
    "    \n",
    "    print(\"\\nData batches generated.\\n\")\n",
    "    \n",
    "    \n",
    "    return train_generator, validation_generator, test_generator, class_weights, steps_per_epoch, validation_steps\n",
    "\n",
    "\n",
    "def get_weight(y):\n",
    "    class_weight_current =  cw.compute_class_weight('balanced', np.unique(y), y)\n",
    "    return class_weight_current\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1822b0",
   "metadata": {},
   "source": [
    "# 5. Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad65f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET MODEL \n",
    "\n",
    "def get_model(model_name, input_shape=(96, 96, 3), num_class=2):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    if model_name == \"Xception\":\n",
    "        base_model = Xception(include_top=False, input_shape=input_shape)\n",
    "    elif model_name == \"ResNet50\":\n",
    "        base_model = ResNet50(include_top=False, input_shape=input_shape)\n",
    "    elif model_name == \"InceptionV3\":\n",
    "        # base_model = InceptionV3(include_top=False, input_shape=input_shape)\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif model_name == \"InceptionResNetV2\":\n",
    "        base_model = InceptionResNetV2(include_top=False, input_shape=input_shape)\n",
    "    if model_name == \"DenseNet201\":\n",
    "        base_model = DenseNet201(include_top=False, input_shape=input_shape)\n",
    "    if model_name == \"NASNetMobile\":\n",
    "        base_model = NASNetMobile(include_top=False, input_shape=input_shape)\n",
    "    if model_name == \"NASNetLarge\":\n",
    "        base_model = NASNetLarge(include_top=False, input_shape=input_shape)\n",
    "    x = base_model(inputs)\n",
    "    \n",
    "    out1 = GlobalMaxPooling2D()(x)\n",
    "    out2 = GlobalAveragePooling2D()(x)\n",
    "    out3 = Flatten()(x)\n",
    "    \n",
    "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
    "    \n",
    "    out = Dropout(0.5)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    \n",
    "    if num_class>1:\n",
    "        out = Dense(num_class, activation=\"softmax\", name=\"3_\")(out)\n",
    "    else:\n",
    "        out = Dense(1, activation=\"sigmoid\", name=\"3_\")(out)\n",
    "        \n",
    "    model = Model(inputs, out)\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "#GET CNN\n",
    "\n",
    "def get_conv_model(num_class=2, input_shape=(3,150,150)):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding=\"same\", input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\"))\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "    model.add(Conv2D(96, (3, 3), padding=\"valid\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(num_class , activation='softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba25fea",
   "metadata": {},
   "source": [
    "## Visualizing Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ef45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(x):\n",
    "    if x==1:\n",
    "        return 'Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())\n",
    "    if x==2:    \n",
    "        return 'Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now())\n",
    "    if x==3:  \n",
    "        return 'Date now: %s' % datetime.datetime.now()\n",
    "    if x==4:  \n",
    "        return 'Date today: %s' % datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e35a89f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create main model directory\n",
      "Could not create main log directory\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "main_model_dir = output_dir + r\"models/\"\n",
    "main_log_dir = output_dir + r\"logs/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(main_model_dir)\n",
    "except:\n",
    "    print(\"Could not create main model directory\")\n",
    "    \n",
    "try:\n",
    "    os.mkdir(main_log_dir)\n",
    "except:\n",
    "    print(\"Could not create main log directory\")\n",
    "\n",
    "\n",
    "\n",
    "model_dir = main_model_dir + time.strftime('%Y-%m-%d %H-%M-%S') + \"/\"\n",
    "log_dir = main_log_dir + time.strftime('%Y-%m-%d %H-%M-%S')\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(model_dir)\n",
    "except:\n",
    "    print(\"Could not create model directory\")\n",
    "    \n",
    "try:\n",
    "    os.mkdir(log_dir)\n",
    "except:\n",
    "    print(\"Could not create log directory\")\n",
    "    \n",
    "model_file = model_dir + \"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d4301b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settting Callbacks...\n"
     ]
    }
   ],
   "source": [
    "print(\"Settting Callbacks...\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    model_file, \n",
    "    monitor='val_acc', \n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.6,\n",
    "    patience=1,\n",
    "    verbose=1)\n",
    "\n",
    "callbacks = [reduce_lr, early_stopping, checkpoint]\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a625984",
   "metadata": {},
   "source": [
    "# 6. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a37f22ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Base Model...\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'stem_conv1/kernel:0' shape=(3, 3, 3, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'stem_bn1/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'stem_bn1/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'reduction_conv_1_stem_1/kernel:0' shape=(1, 1, 32, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'reduction_bn_1_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'reduction_bn_1_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right1_stem_1/depthwise_kernel:0' shape=(7, 7, 32, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right1_stem_1/pointwise_kernel:0' shape=(1, 1, 32, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_left1_stem_1/depthwise_kernel:0' shape=(5, 5, 11, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_left1_stem_1/pointwise_kernel:0' shape=(1, 1, 11, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right1_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right1_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left1_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left1_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right1_stem_1/depthwise_kernel:0' shape=(7, 7, 11, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right1_stem_1/pointwise_kernel:0' shape=(1, 1, 11, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_left1_stem_1/depthwise_kernel:0' shape=(5, 5, 11, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_left1_stem_1/pointwise_kernel:0' shape=(1, 1, 11, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left1_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left1_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_5), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right1_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right1_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right2_stem_1/depthwise_kernel:0' shape=(7, 7, 32, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right2_stem_1/pointwise_kernel:0' shape=(1, 1, 32, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_5), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_left4_stem_1/depthwise_kernel:0' shape=(3, 3, 11, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_left4_stem_1/pointwise_kernel:0' shape=(1, 1, 11, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_6), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right3_stem_1/depthwise_kernel:0' shape=(5, 5, 32, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right3_stem_1/pointwise_kernel:0' shape=(1, 1, 32, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_6), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right2_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right2_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_7), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left4_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left4_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_8), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right3_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right3_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_7), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right2_stem_1/depthwise_kernel:0' shape=(7, 7, 11, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right2_stem_1/pointwise_kernel:0' shape=(1, 1, 11, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_8), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_left4_stem_1/depthwise_kernel:0' shape=(3, 3, 11, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_left4_stem_1/pointwise_kernel:0' shape=(1, 1, 11, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_9), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right3_stem_1/depthwise_kernel:0' shape=(5, 5, 11, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right3_stem_1/pointwise_kernel:0' shape=(1, 1, 11, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_9), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right2_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right2_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_10), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left4_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left4_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_11), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right3_stem_1/gamma:0' shape=(11,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right3_stem_1/beta:0' shape=(11,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_1_stem_2/kernel:0' shape=(1, 1, 32, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_2_stem_2/kernel:0' shape=(1, 1, 32, 11) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'reduction_conv_1_stem_2/kernel:0' shape=(1, 1, 44, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_12), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_13), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'reduction_bn_1_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'reduction_bn_1_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_10), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right1_stem_2/depthwise_kernel:0' shape=(7, 7, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right1_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_11), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_left1_stem_2/depthwise_kernel:0' shape=(5, 5, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_left1_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_14), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right1_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right1_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left1_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left1_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_12), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right1_stem_2/depthwise_kernel:0' shape=(7, 7, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right1_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_13), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_left1_stem_2/depthwise_kernel:0' shape=(5, 5, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_left1_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left1_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left1_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_17), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right1_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right1_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_14), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right2_stem_2/depthwise_kernel:0' shape=(7, 7, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right2_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_left4_stem_2/depthwise_kernel:0' shape=(3, 3, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_left4_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right3_stem_2/depthwise_kernel:0' shape=(5, 5, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right3_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_18), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right2_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right2_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_19), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left4_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left4_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_20), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right3_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right3_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_17), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right2_stem_2/depthwise_kernel:0' shape=(7, 7, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right2_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_18), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_left4_stem_2/depthwise_kernel:0' shape=(3, 3, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_left4_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_19), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right3_stem_2/depthwise_kernel:0' shape=(5, 5, 22, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right3_stem_2/pointwise_kernel:0' shape=(1, 1, 22, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_21), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right2_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right2_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_22), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left4_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left4_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_23), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right3_stem_2/gamma:0' shape=(22,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right3_stem_2/beta:0' shape=(22,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_5), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_1_0/kernel:0' shape=(1, 1, 44, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_6), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_2_0/kernel:0' shape=(1, 1, 44, 22) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_7), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_0/kernel:0' shape=(1, 1, 88, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_24), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_25), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_20), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_0/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_21), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_0/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_22), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_0/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_23), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_0/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_24), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_0/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_26), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_27), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_28), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_29), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_30), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_25), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_0/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_26), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_0/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_27), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_0/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_28), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_0/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_29), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_0/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_0/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_31), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_32), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_33), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_34), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_35), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_0/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_0/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_8), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_1/kernel:0' shape=(1, 1, 264, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_9), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_1/kernel:0' shape=(1, 1, 88, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_36), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_37), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_30), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_1/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_31), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_1/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_32), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_1/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_33), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_1/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_34), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_1/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_38), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_39), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_40), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_41), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_42), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_35), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_1/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_36), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_1/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_37), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_1/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_38), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_1/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_39), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_1/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_1/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_43), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_44), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_45), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_46), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_47), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_1/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_1/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_10), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_2/kernel:0' shape=(1, 1, 264, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_11), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_2/kernel:0' shape=(1, 1, 264, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_48), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_49), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_40), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_2/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_41), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_2/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_42), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_2/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_43), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_2/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_44), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_2/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_50), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_51), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_52), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_53), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_54), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_45), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_2/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_46), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_2/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_47), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_2/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_48), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_2/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_49), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_2/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_2/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_55), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_56), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_57), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_58), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_59), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_2/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_2/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_12), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_3/kernel:0' shape=(1, 1, 264, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_13), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_3/kernel:0' shape=(1, 1, 264, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_60), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_61), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_50), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_3/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_51), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_3/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_52), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_3/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_53), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_3/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_54), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_3/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_62), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_63), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_64), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_65), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_66), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_55), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_3/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_56), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_3/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_57), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_3/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_58), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_3/depthwise_kernel:0' shape=(3, 3, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_59), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_3/depthwise_kernel:0' shape=(5, 5, 44, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_3/pointwise_kernel:0' shape=(1, 1, 44, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_67), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_68), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_69), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_70), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_71), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_3/gamma:0' shape=(44,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_3/beta:0' shape=(44,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_14), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_reduce_4/kernel:0' shape=(1, 1, 264, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'reduction_conv_1_reduce_4/kernel:0' shape=(1, 1, 264, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_72), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_73), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'reduction_bn_1_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'reduction_bn_1_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_60), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right1_reduce_4/depthwise_kernel:0' shape=(7, 7, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right1_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_61), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_left1_reduce_4/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_left1_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_74), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right1_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right1_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_75), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left1_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left1_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_62), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right1_reduce_4/depthwise_kernel:0' shape=(7, 7, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right1_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_63), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_left1_reduce_4/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_left1_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_76), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left1_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left1_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_77), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right1_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right1_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_64), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right2_reduce_4/depthwise_kernel:0' shape=(7, 7, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right2_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_65), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_left4_reduce_4/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_left4_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_66), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right3_reduce_4/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right3_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_78), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right2_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right2_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_79), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left4_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left4_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_80), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right3_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right3_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_67), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right2_reduce_4/depthwise_kernel:0' shape=(7, 7, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right2_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_68), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_left4_reduce_4/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_left4_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_69), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right3_reduce_4/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right3_reduce_4/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_81), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right2_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right2_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_82), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left4_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left4_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_83), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right3_reduce_4/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right3_reduce_4/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_1_5/kernel:0' shape=(1, 1, 264, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_17), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_2_5/kernel:0' shape=(1, 1, 264, 44) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_18), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_5/kernel:0' shape=(1, 1, 352, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_84), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_85), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_70), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_5/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_71), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_5/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_72), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_5/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_73), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_5/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_74), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_5/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_86), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_87), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_88), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_89), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_90), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_75), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_5/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_76), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_5/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_77), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_5/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_78), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_5/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_79), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_5/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_5/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_91), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_92), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_93), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_94), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_95), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_5/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_5/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_19), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_6/kernel:0' shape=(1, 1, 528, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_20), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_6/kernel:0' shape=(1, 1, 352, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_96), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_97), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_80), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_6/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_81), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_6/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_82), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_6/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_83), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_6/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_84), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_6/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_98), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_99), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_100), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_101), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_102), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_85), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_6/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_86), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_6/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_87), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_6/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_88), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_6/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_89), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_6/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_6/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_103), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_104), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_105), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_106), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_107), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_6/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_6/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_21), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_7/kernel:0' shape=(1, 1, 528, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_22), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_7/kernel:0' shape=(1, 1, 528, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_108), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_109), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_90), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_7/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_91), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_7/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_92), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_7/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_93), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_7/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_94), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_7/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_110), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_111), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_112), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_113), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_114), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_95), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_7/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_96), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_7/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_97), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_7/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_98), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_7/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_99), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_7/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_7/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_115), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_116), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_117), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_118), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_119), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_7/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_7/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_23), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_8/kernel:0' shape=(1, 1, 528, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_24), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_8/kernel:0' shape=(1, 1, 528, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_120), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_121), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_100), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_8/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_101), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_8/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_102), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_8/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_103), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_8/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_104), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_8/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_122), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_123), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_124), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_125), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_126), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_105), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_8/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_106), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_8/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_107), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_8/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_108), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_8/depthwise_kernel:0' shape=(3, 3, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_109), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_8/depthwise_kernel:0' shape=(5, 5, 88, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_8/pointwise_kernel:0' shape=(1, 1, 88, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_127), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_128), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_129), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_130), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_131), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_8/gamma:0' shape=(88,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_8/beta:0' shape=(88,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_25), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_reduce_8/kernel:0' shape=(1, 1, 528, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_26), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'reduction_conv_1_reduce_8/kernel:0' shape=(1, 1, 528, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_132), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_133), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'reduction_bn_1_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'reduction_bn_1_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_110), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right1_reduce_8/depthwise_kernel:0' shape=(7, 7, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right1_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_111), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_left1_reduce_8/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_left1_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_134), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right1_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right1_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_135), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left1_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left1_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_112), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right1_reduce_8/depthwise_kernel:0' shape=(7, 7, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right1_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_113), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_left1_reduce_8/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_left1_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_136), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left1_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left1_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_137), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right1_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right1_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_114), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right2_reduce_8/depthwise_kernel:0' shape=(7, 7, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right2_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_115), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_left4_reduce_8/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_left4_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_116), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_reduction_right3_reduce_8/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_reduction_right3_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_138), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right2_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right2_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_139), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left4_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_left4_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_140), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right3_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_reduction_right3_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_117), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right2_reduce_8/depthwise_kernel:0' shape=(7, 7, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right2_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_118), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_left4_reduce_8/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_left4_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_119), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_reduction_right3_reduce_8/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_reduction_right3_reduce_8/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_141), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right2_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right2_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_142), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left4_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_left4_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_143), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right3_reduce_8/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_reduction_right3_reduce_8/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_27), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_1_9/kernel:0' shape=(1, 1, 528, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_28), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_2_9/kernel:0' shape=(1, 1, 528, 88) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_29), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_9/kernel:0' shape=(1, 1, 704, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_144), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_145), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_120), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_9/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_121), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_9/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_122), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_9/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_123), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_9/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_124), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_9/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_146), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_147), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_148), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_149), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_150), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_125), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_9/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_126), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_9/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_127), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_9/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_128), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_9/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_129), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_9/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_9/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_151), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_152), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_153), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_154), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_155), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_9/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_9/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_30), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_10/kernel:0' shape=(1, 1, 1056, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_31), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_10/kernel:0' shape=(1, 1, 704, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_156), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_157), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_130), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_10/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_131), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_10/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_132), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_10/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_133), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_10/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_134), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_10/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_158), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_159), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_160), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_161), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_162), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_135), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_10/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_136), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_10/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_137), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_10/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_138), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_10/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_139), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_10/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_10/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_163), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_164), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_165), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_166), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_167), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_10/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_10/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_32), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_11/kernel:0' shape=(1, 1, 1056, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_33), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_11/kernel:0' shape=(1, 1, 1056, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_168), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_169), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_140), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_11/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_141), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_11/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_142), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_11/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_143), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_11/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_144), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_11/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_170), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_171), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_172), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_173), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_174), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_145), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_11/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_146), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_11/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_147), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_11/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_148), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_11/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_149), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_11/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_11/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_175), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_176), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_177), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_178), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_179), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_11/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_11/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_34), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_conv_1_12/kernel:0' shape=(1, 1, 1056, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_35), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_conv_projection_12/kernel:0' shape=(1, 1, 1056, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_180), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'adjust_bn_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'adjust_bn_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_181), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'normal_bn_1_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'normal_bn_1_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_150), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_12/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left5_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_151), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_12/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right2_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_152), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_12/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left2_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_153), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_12/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_right1_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_154), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_12/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_normal_left1_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_182), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left5_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_183), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right2_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_184), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left2_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_185), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_right1_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_186), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_1_bn_normal_left1_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_155), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_12/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left5_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_156), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_12/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right2_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_157), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_12/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left2_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_158), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_12/depthwise_kernel:0' shape=(3, 3, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_right1_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.separable_conv2d_159), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_12/depthwise_kernel:0' shape=(5, 5, 176, 1) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_normal_left1_12/pointwise_kernel:0' shape=(1, 1, 176, 176) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_187), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left5_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_188), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left2_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_189), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right2_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_190), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_left1_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_191), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_12/gamma:0' shape=(176,) dtype=float32>\n",
      "  <tf.Variable 'separable_conv_2_bn_normal_right1_12/beta:0' shape=(176,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution (TFOpLambda)  (None, 111, 111, 32) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 111, 111, 32 0           tf.nn.convolution[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu (TFOpLambda)         (None, 111, 111, 32) 0           tf.compat.v1.nn.fused_batch_norm[\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_1 (TFOpLambda (None, 111, 111, 11) 0           tf.nn.relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 111, 111, 11 0           tf.nn.convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_2 (TFOpLambda)       (None, 111, 111, 11) 0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1 (TFOpLambda)       (None, 111, 111, 32) 0           tf.compat.v1.nn.fused_batch_norm[\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_1 (TFOpLambda) (None, 115, 115, 11) 0           tf.nn.relu_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad (TFOpLambda)   (None, 117, 117, 32) 0           tf.nn.relu_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.compat.v1.pad_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.compat.v1.pad[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d[\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_4 (TFOpLambda)       (None, 56, 56, 11)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_3 (TFOpLambda)       (None, 56, 56, 11)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.nn.relu_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.nn.relu_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_5 (TFOpLambda)       (None, 111, 111, 32) 0           tf.compat.v1.nn.fused_batch_norm[\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_2 (TFOpLambda) (None, 117, 117, 32) 0           tf.nn.relu_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_6 (TFOpLambda)       (None, 111, 111, 32) 0           tf.compat.v1.nn.fused_batch_norm[\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 56, 56, 11)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.compat.v1.pad_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_3 (TFOpLambda) (None, 115, 115, 32) 0           tf.nn.relu_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_7 (TFOpLambda)       (None, 56, 56, 11)   0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.compat.v1.pad_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.nn.relu_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_8 (TFOpLambda)       (None, 56, 56, 11)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_4 (TFOpLambda) (None, 113, 113, 11) 0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.nn.relu_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_10 (TFOpLambda)      (None, 56, 56, 11)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_9 (TFOpLambda)       (None, 56, 56, 11)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.max_pool (TFOpL (None, 56, 56, 11)   0           tf.compat.v1.pad_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.nn.relu_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 56, 56, 11)   0           tf.nn.relu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_11 (TFOpLambda)      (None, 111, 111, 32) 0           tf.compat.v1.nn.fused_batch_norm[\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 56, 56, 11)   0           tf.compat.v1.nn.max_pool[0][0]   \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_1 (TFO (None, 56, 56, 11)   0           tf.compat.v1.pad_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool (TFOpL (None, 56, 56, 11)   0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 11), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.max_pool_1 (TFO (None, 56, 56, 11)   0           tf.compat.v1.pad_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_5 (TFOpLambda) (None, 112, 112, 32) 0           tf.nn.relu_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 56, 56, 11)   0           tf.compat.v1.nn.avg_pool_1[0][0] \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 56, 56, 11)   0           tf.__operators__.add_1[0][0]     \n",
      "                                                                 tf.compat.v1.nn.avg_pool[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 56, 56, 11)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.max_pool_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 111, 111, 32) 0           tf.compat.v1.pad_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 56, 56, 44)   0           tf.__operators__.add_1[0][0]     \n",
      "                                                                 tf.__operators__.add_2[0][0]     \n",
      "                                                                 tf.__operators__.add_3[0][0]     \n",
      "                                                                 tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_3 (TFO (None, 56, 56, 32)   0           tf.nn.relu_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_2 (TFO (None, 56, 56, 32)   0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_12 (TFOpLambda)      (None, 56, 56, 44)   0           tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_2 (TFOpLambda (None, 56, 56, 11)   0           tf.compat.v1.nn.avg_pool_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_3 (TFOpLambda (None, 56, 56, 11)   0           tf.compat.v1.nn.avg_pool_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_4 (TFOpLambda (None, 56, 56, 22)   0           tf.nn.relu_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 56, 56, 22)   0           tf.nn.convolution_2[0][0]        \n",
      "                                                                 tf.nn.convolution_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 22), 0           tf.nn.convolution_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 56, 56, 22), 0           tf.concat_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_14 (TFOpLambda)      (None, 56, 56, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_13 (TFOpLambda)      (None, 56, 56, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_7 (TFOpLambda) (None, 59, 59, 22)   0           tf.nn.relu_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_6 (TFOpLambda) (None, 61, 61, 22)   0           tf.nn.relu_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.compat.v1.pad_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.compat.v1.pad_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_16 (TFOpLambda)      (None, 28, 28, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_15 (TFOpLambda)      (None, 28, 28, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.nn.relu_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.nn.relu_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_17 (TFOpLambda)      (None, 56, 56, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_8 (TFOpLambda) (None, 61, 61, 22)   0           tf.nn.relu_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_18 (TFOpLambda)      (None, 56, 56, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 28, 28, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.compat.v1.pad_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_9 (TFOpLambda) (None, 59, 59, 22)   0           tf.nn.relu_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_19 (TFOpLambda)      (None, 28, 28, 22)   0           tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.compat.v1.pad_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.nn.relu_19[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_20 (TFOpLambda)      (None, 28, 28, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_10 (TFOpLambda (None, 57, 57, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.nn.relu_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_22 (TFOpLambda)      (None, 28, 28, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_21 (TFOpLambda)      (None, 28, 28, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.max_pool_2 (TFO (None, 28, 28, 22)   0           tf.compat.v1.pad_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.nn.relu_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 22)   0           tf.nn.relu_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_23 (TFOpLambda)      (None, 56, 56, 44)   0           tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 28, 28, 22)   0           tf.compat.v1.nn.max_pool_2[0][0] \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_5 (TFO (None, 28, 28, 22)   0           tf.compat.v1.pad_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_4 (TFO (None, 28, 28, 22)   0           tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 22), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.max_pool_3 (TFO (None, 28, 28, 22)   0           tf.compat.v1.pad_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_11 (TFOpLambda (None, 57, 57, 44)   0           tf.nn.relu_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 28, 28, 22)   0           tf.compat.v1.nn.avg_pool_5[0][0] \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 28, 28, 22)   0           tf.__operators__.add_6[0][0]     \n",
      "                                                                 tf.compat.v1.nn.avg_pool_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 28, 28, 22)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.max_pool_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 56, 56, 44)   0           tf.compat.v1.pad_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_2 (TFOpLambda)        (None, 28, 28, 88)   0           tf.__operators__.add_6[0][0]     \n",
      "                                                                 tf.__operators__.add_7[0][0]     \n",
      "                                                                 tf.__operators__.add_8[0][0]     \n",
      "                                                                 tf.__operators__.add_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_7 (TFO (None, 28, 28, 44)   0           tf.nn.relu_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_6 (TFO (None, 28, 28, 44)   0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_5 (TFOpLambda (None, 28, 28, 22)   0           tf.compat.v1.nn.avg_pool_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_6 (TFOpLambda (None, 28, 28, 22)   0           tf.compat.v1.nn.avg_pool_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_24 (TFOpLambda)      (None, 28, 28, 88)   0           tf.concat_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_3 (TFOpLambda)        (None, 28, 28, 44)   0           tf.nn.convolution_5[0][0]        \n",
      "                                                                 tf.nn.convolution_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_7 (TFOpLambda (None, 28, 28, 44)   0           tf.nn.relu_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.concat_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.nn.convolution_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_29 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_28 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_27 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_26 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_25 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_34 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_33 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.nn.relu_32 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_31 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_30 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_10 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_8 (TFO (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_9 (TFO (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_10 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_11 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.avg_pool_10[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_13 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.avg_pool_8[0][0] \n",
      "                                                                 tf.compat.v1.nn.avg_pool_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_14 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_4 (TFOpLambda)        (None, 28, 28, 264)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_10[0][0]    \n",
      "                                                                 tf.__operators__.add_11[0][0]    \n",
      "                                                                 tf.__operators__.add_12[0][0]    \n",
      "                                                                 tf.__operators__.add_13[0][0]    \n",
      "                                                                 tf.__operators__.add_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_36 (TFOpLambda)      (None, 28, 28, 88)   0           tf.concat_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_35 (TFOpLambda)      (None, 28, 28, 264)  0           tf.concat_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_9 (TFOpLambda (None, 28, 28, 44)   0           tf.nn.relu_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_8 (TFOpLambda (None, 28, 28, 44)   0           tf.nn.relu_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.nn.convolution_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.nn.convolution_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_41 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_40 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_39 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_38 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_37 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_46 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_45 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_44 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_43 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_42 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_13 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_11 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_12 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_15 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_16 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_17 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.avg_pool_13[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_18 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.avg_pool_11[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_19 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_5 (TFOpLambda)        (None, 28, 28, 264)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_15[0][0]    \n",
      "                                                                 tf.__operators__.add_16[0][0]    \n",
      "                                                                 tf.__operators__.add_17[0][0]    \n",
      "                                                                 tf.__operators__.add_18[0][0]    \n",
      "                                                                 tf.__operators__.add_19[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.nn.relu_48 (TFOpLambda)      (None, 28, 28, 264)  0           tf.concat_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_47 (TFOpLambda)      (None, 28, 28, 264)  0           tf.concat_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_11 (TFOpLambd (None, 28, 28, 44)   0           tf.nn.relu_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_10 (TFOpLambd (None, 28, 28, 44)   0           tf.nn.relu_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.nn.convolution_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.nn.convolution_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_53 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_52 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_51 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_50 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_49 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_58 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_57 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_56 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_55 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_54 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_16 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_14 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_15 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_20 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_21 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_22 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.avg_pool_16[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_23 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.avg_pool_14[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_24 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_6 (TFOpLambda)        (None, 28, 28, 264)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_20[0][0]    \n",
      "                                                                 tf.__operators__.add_21[0][0]    \n",
      "                                                                 tf.__operators__.add_22[0][0]    \n",
      "                                                                 tf.__operators__.add_23[0][0]    \n",
      "                                                                 tf.__operators__.add_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_60 (TFOpLambda)      (None, 28, 28, 264)  0           tf.concat_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_59 (TFOpLambda)      (None, 28, 28, 264)  0           tf.concat_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_13 (TFOpLambd (None, 28, 28, 44)   0           tf.nn.relu_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_12 (TFOpLambd (None, 28, 28, 44)   0           tf.nn.relu_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.nn.convolution_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.nn.convolution_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_65 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_64 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_63 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_62 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_61 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_70 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_69 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_68 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_67 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_66 (TFOpLambda)      (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 28, 28, 44)   0           tf.nn.relu_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_19 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_17 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_18 (TF (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 44), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_25 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_26 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_27 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.avg_pool_19[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_28 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.avg_pool_17[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_18[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_29 (TFOpLa (None, 28, 28, 44)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_7 (TFOpLambda)        (None, 28, 28, 264)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_25[0][0]    \n",
      "                                                                 tf.__operators__.add_26[0][0]    \n",
      "                                                                 tf.__operators__.add_27[0][0]    \n",
      "                                                                 tf.__operators__.add_28[0][0]    \n",
      "                                                                 tf.__operators__.add_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_72 (TFOpLambda)      (None, 28, 28, 264)  0           tf.concat_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_71 (TFOpLambda)      (None, 28, 28, 264)  0           tf.concat_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_15 (TFOpLambd (None, 28, 28, 88)   0           tf.nn.relu_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_14 (TFOpLambd (None, 28, 28, 88)   0           tf.nn.relu_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 88), 0           tf.nn.convolution_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 88), 0           tf.nn.convolution_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_74 (TFOpLambda)      (None, 28, 28, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_73 (TFOpLambda)      (None, 28, 28, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_13 (TFOpLambda (None, 31, 31, 88)   0           tf.nn.relu_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_12 (TFOpLambda (None, 33, 33, 88)   0           tf.nn.relu_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.compat.v1.pad_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.compat.v1.pad_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_76 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_75 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_77 (TFOpLambda)      (None, 28, 28, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_14 (TFOpLambda (None, 33, 33, 88)   0           tf.nn.relu_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_78 (TFOpLambda)      (None, 28, 28, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_30 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.compat.v1.pad_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_15 (TFOpLambda (None, 31, 31, 88)   0           tf.nn.relu_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_79 (TFOpLambda)      (None, 14, 14, 88)   0           tf.__operators__.add_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.compat.v1.pad_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_80 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_16 (TFOpLambda (None, 29, 29, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_82 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_81 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.max_pool_4 (TFO (None, 14, 14, 88)   0           tf.compat.v1.pad_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_83 (TFOpLambda)      (None, 28, 28, 264)  0           tf.concat_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_31 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.max_pool_4[0][0] \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_21 (TF (None, 14, 14, 88)   0           tf.compat.v1.pad_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_20 (TF (None, 14, 14, 88)   0           tf.__operators__.add_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.max_pool_5 (TFO (None, 14, 14, 88)   0           tf.compat.v1.pad_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_17 (TFOpLambda (None, 29, 29, 264)  0           tf.nn.relu_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_32 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.avg_pool_21[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_33 (TFOpLa (None, 14, 14, 88)   0           tf.__operators__.add_31[0][0]    \n",
      "                                                                 tf.compat.v1.nn.avg_pool_20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_34 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.max_pool_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 28, 28, 264)  0           tf.compat.v1.pad_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_8 (TFOpLambda)        (None, 14, 14, 352)  0           tf.__operators__.add_31[0][0]    \n",
      "                                                                 tf.__operators__.add_32[0][0]    \n",
      "                                                                 tf.__operators__.add_33[0][0]    \n",
      "                                                                 tf.__operators__.add_34[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_23 (TF (None, 14, 14, 264)  0           tf.nn.relu_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_22 (TF (None, 14, 14, 264)  0           tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_16 (TFOpLambd (None, 14, 14, 44)   0           tf.compat.v1.nn.avg_pool_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_17 (TFOpLambd (None, 14, 14, 44)   0           tf.compat.v1.nn.avg_pool_22[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_84 (TFOpLambda)      (None, 14, 14, 352)  0           tf.concat_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_9 (TFOpLambda)        (None, 14, 14, 88)   0           tf.nn.convolution_16[0][0]       \n",
      "                                                                 tf.nn.convolution_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_18 (TFOpLambd (None, 14, 14, 88)   0           tf.nn.relu_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.concat_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.nn.convolution_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_89 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_88 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_87 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_86 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_85 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_94 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_93 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_92 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_91 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_90 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_26 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_24 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_25 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_35 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_36 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_37 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.avg_pool_26[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_38 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.avg_pool_24[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_39 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_10 (TFOpLambda)       (None, 14, 14, 528)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_35[0][0]    \n",
      "                                                                 tf.__operators__.add_36[0][0]    \n",
      "                                                                 tf.__operators__.add_37[0][0]    \n",
      "                                                                 tf.__operators__.add_38[0][0]    \n",
      "                                                                 tf.__operators__.add_39[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_96 (TFOpLambda)      (None, 14, 14, 352)  0           tf.concat_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_95 (TFOpLambda)      (None, 14, 14, 528)  0           tf.concat_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_20 (TFOpLambd (None, 14, 14, 88)   0           tf.nn.relu_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_19 (TFOpLambd (None, 14, 14, 88)   0           tf.nn.relu_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.nn.convolution_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.nn.convolution_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_101 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_100 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_99 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_98 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_97 (TFOpLambda)      (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_106 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_105 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_104 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_103 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_102 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_29 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_27 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_28 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_40 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_41 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_42 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.avg_pool_29[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_43 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.avg_pool_27[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_28[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_44 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_11 (TFOpLambda)       (None, 14, 14, 528)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_40[0][0]    \n",
      "                                                                 tf.__operators__.add_41[0][0]    \n",
      "                                                                 tf.__operators__.add_42[0][0]    \n",
      "                                                                 tf.__operators__.add_43[0][0]    \n",
      "                                                                 tf.__operators__.add_44[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_108 (TFOpLambda)     (None, 14, 14, 528)  0           tf.concat_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_107 (TFOpLambda)     (None, 14, 14, 528)  0           tf.concat_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_22 (TFOpLambd (None, 14, 14, 88)   0           tf.nn.relu_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_21 (TFOpLambd (None, 14, 14, 88)   0           tf.nn.relu_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.nn.convolution_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.nn.convolution_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_113 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_112 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_111 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_110 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_109 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_118 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_117 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_116 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_115 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_114 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_32 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_30 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_31 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_45 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_46 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_47 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.avg_pool_32[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_48 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.avg_pool_30[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_31[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_49 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_12 (TFOpLambda)       (None, 14, 14, 528)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_45[0][0]    \n",
      "                                                                 tf.__operators__.add_46[0][0]    \n",
      "                                                                 tf.__operators__.add_47[0][0]    \n",
      "                                                                 tf.__operators__.add_48[0][0]    \n",
      "                                                                 tf.__operators__.add_49[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_120 (TFOpLambda)     (None, 14, 14, 528)  0           tf.concat_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_119 (TFOpLambda)     (None, 14, 14, 528)  0           tf.concat_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_24 (TFOpLambd (None, 14, 14, 88)   0           tf.nn.relu_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_23 (TFOpLambd (None, 14, 14, 88)   0           tf.nn.relu_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.nn.convolution_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.nn.convolution_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_125 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_124 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_123 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_122 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_121 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_130 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_129 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_128 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_127 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_126 (TFOpLambda)     (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 14, 14, 88)   0           tf.nn.relu_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_35 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_33 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_34 (TF (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 88), 0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_50 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_51 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_52 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.avg_pool_35[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_53 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.avg_pool_33[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_34[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_54 (TFOpLa (None, 14, 14, 88)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_13 (TFOpLambda)       (None, 14, 14, 528)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_50[0][0]    \n",
      "                                                                 tf.__operators__.add_51[0][0]    \n",
      "                                                                 tf.__operators__.add_52[0][0]    \n",
      "                                                                 tf.__operators__.add_53[0][0]    \n",
      "                                                                 tf.__operators__.add_54[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_132 (TFOpLambda)     (None, 14, 14, 528)  0           tf.concat_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_131 (TFOpLambda)     (None, 14, 14, 528)  0           tf.concat_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_26 (TFOpLambd (None, 14, 14, 176)  0           tf.nn.relu_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_25 (TFOpLambd (None, 14, 14, 176)  0           tf.nn.relu_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 176) 0           tf.nn.convolution_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 176) 0           tf.nn.convolution_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_134 (TFOpLambda)     (None, 14, 14, 176)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_133 (TFOpLambda)     (None, 14, 14, 176)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_19 (TFOpLambda (None, 17, 17, 176)  0           tf.nn.relu_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_18 (TFOpLambda (None, 19, 19, 176)  0           tf.nn.relu_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.compat.v1.pad_19[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.compat.v1.pad_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_136 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_135 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_137 (TFOpLambda)     (None, 14, 14, 176)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_20 (TFOpLambda (None, 19, 19, 176)  0           tf.nn.relu_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_138 (TFOpLambda)     (None, 14, 14, 176)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_55 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.compat.v1.pad_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_21 (TFOpLambda (None, 17, 17, 176)  0           tf.nn.relu_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_139 (TFOpLambda)     (None, 7, 7, 176)    0           tf.__operators__.add_55[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.compat.v1.pad_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_140 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_22 (TFOpLambda (None, 15, 15, 176)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_142 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_141 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.max_pool_6 (TFO (None, 7, 7, 176)    0           tf.compat.v1.pad_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_143 (TFOpLambda)     (None, 14, 14, 528)  0           tf.concat_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_56 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.max_pool_6[0][0] \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_37 (TF (None, 7, 7, 176)    0           tf.compat.v1.pad_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_36 (TF (None, 7, 7, 176)    0           tf.__operators__.add_55[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.max_pool_7 (TFO (None, 7, 7, 176)    0           tf.compat.v1.pad_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_23 (TFOpLambda (None, 15, 15, 528)  0           tf.nn.relu_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_57 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.avg_pool_37[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_58 (TFOpLa (None, 7, 7, 176)    0           tf.__operators__.add_56[0][0]    \n",
      "                                                                 tf.compat.v1.nn.avg_pool_36[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_59 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.max_pool_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 14, 14, 528)  0           tf.compat.v1.pad_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_14 (TFOpLambda)       (None, 7, 7, 704)    0           tf.__operators__.add_56[0][0]    \n",
      "                                                                 tf.__operators__.add_57[0][0]    \n",
      "                                                                 tf.__operators__.add_58[0][0]    \n",
      "                                                                 tf.__operators__.add_59[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_39 (TF (None, 7, 7, 528)    0           tf.nn.relu_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_38 (TF (None, 7, 7, 528)    0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_27 (TFOpLambd (None, 7, 7, 88)     0           tf.compat.v1.nn.avg_pool_39[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_28 (TFOpLambd (None, 7, 7, 88)     0           tf.compat.v1.nn.avg_pool_38[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_144 (TFOpLambda)     (None, 7, 7, 704)    0           tf.concat_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_15 (TFOpLambda)       (None, 7, 7, 176)    0           tf.nn.convolution_27[0][0]       \n",
      "                                                                 tf.nn.convolution_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_29 (TFOpLambd (None, 7, 7, 176)    0           tf.nn.relu_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.concat_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.nn.convolution_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_149 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_148 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_147 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_146 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_145 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_154 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_153 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_152 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_151 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_150 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_42 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_40 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_41 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_60 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_61 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_62 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.avg_pool_42[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_63 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.avg_pool_40[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_41[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_64 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_16 (TFOpLambda)       (None, 7, 7, 1056)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_60[0][0]    \n",
      "                                                                 tf.__operators__.add_61[0][0]    \n",
      "                                                                 tf.__operators__.add_62[0][0]    \n",
      "                                                                 tf.__operators__.add_63[0][0]    \n",
      "                                                                 tf.__operators__.add_64[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_156 (TFOpLambda)     (None, 7, 7, 704)    0           tf.concat_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_155 (TFOpLambda)     (None, 7, 7, 1056)   0           tf.concat_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_31 (TFOpLambd (None, 7, 7, 176)    0           tf.nn.relu_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_30 (TFOpLambd (None, 7, 7, 176)    0           tf.nn.relu_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.nn.convolution_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.nn.convolution_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_161 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_160 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_159 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_158 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_157 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_166 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_165 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_164 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_163 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_162 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_45 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_43 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_44 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_65 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_66 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_67 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.avg_pool_45[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_68 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.avg_pool_43[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_44[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_69 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_17 (TFOpLambda)       (None, 7, 7, 1056)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_65[0][0]    \n",
      "                                                                 tf.__operators__.add_66[0][0]    \n",
      "                                                                 tf.__operators__.add_67[0][0]    \n",
      "                                                                 tf.__operators__.add_68[0][0]    \n",
      "                                                                 tf.__operators__.add_69[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_168 (TFOpLambda)     (None, 7, 7, 1056)   0           tf.concat_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_167 (TFOpLambda)     (None, 7, 7, 1056)   0           tf.concat_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_33 (TFOpLambd (None, 7, 7, 176)    0           tf.nn.relu_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_32 (TFOpLambd (None, 7, 7, 176)    0           tf.nn.relu_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.nn.convolution_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.nn.convolution_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_173 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_172 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_171 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_170 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_169 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_178 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_177 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_176 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_175 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_174 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_48 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_46 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_47 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_70 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_71 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_72 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.avg_pool_48[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_73 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.avg_pool_46[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_47[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_74 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_18 (TFOpLambda)       (None, 7, 7, 1056)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_70[0][0]    \n",
      "                                                                 tf.__operators__.add_71[0][0]    \n",
      "                                                                 tf.__operators__.add_72[0][0]    \n",
      "                                                                 tf.__operators__.add_73[0][0]    \n",
      "                                                                 tf.__operators__.add_74[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_180 (TFOpLambda)     (None, 7, 7, 1056)   0           tf.concat_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_179 (TFOpLambda)     (None, 7, 7, 1056)   0           tf.concat_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_35 (TFOpLambd (None, 7, 7, 176)    0           tf.nn.relu_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_34 (TFOpLambd (None, 7, 7, 176)    0           tf.nn.relu_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.nn.convolution_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.nn.convolution_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_185 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_184 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_183 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_182 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_181 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_190 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_189 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_188 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_187 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_186 (TFOpLambda)     (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.separable_conv2 (None, 7, 7, 176)    0           tf.nn.relu_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_51 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_49 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.avg_pool_50 (TF (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 176),  0           tf.compat.v1.nn.separable_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_75 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_76 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_77 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.avg_pool_51[0][0]\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_78 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.avg_pool_49[0][0]\n",
      "                                                                 tf.compat.v1.nn.avg_pool_50[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_79 (TFOpLa (None, 7, 7, 176)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_19 (TFOpLambda)       (None, 7, 7, 1056)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.__operators__.add_75[0][0]    \n",
      "                                                                 tf.__operators__.add_76[0][0]    \n",
      "                                                                 tf.__operators__.add_77[0][0]    \n",
      "                                                                 tf.__operators__.add_78[0][0]    \n",
      "                                                                 tf.__operators__.add_79[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_191 (TFOpLambda)     (None, 7, 7, 1056)   0           tf.concat_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 1056)         0           tf.nn.relu_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1056)         0           tf.nn.relu_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 51744)        0           tf.nn.relu_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 53856)        0           global_max_pooling2d[0][0]       \n",
      "                                                                 global_average_pooling2d[0][0]   \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 53856)        0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 53856)        215424      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 2)            107714      batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 323,138\n",
      "Trainable params: 215,426\n",
      "Non-trainable params: 107,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting Base Model...\")\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "num_class = 2\n",
    "model = get_model(model_name=\"NASNetMobile\", input_shape=input_shape, num_class=num_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2790149",
   "metadata": {},
   "source": [
    "## Loss and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fab39af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.AUC at 0x7fc98717caf0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 'categorical_crossentropy'\n",
    "metrics=[tf.keras.metrics.SensitivityAtSpecificity(0.95)]\n",
    "\n",
    "# metrics = [auroc]\n",
    "tf.keras.metrics.AUC(num_thresholds=200, curve='ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea73d6",
   "metadata": {},
   "source": [
    "# 7. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b0546f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data following preprocessing...\n",
      "\n",
      "Found 38 validated image filenames belonging to 2 classes.\n",
      "Found 12 validated image filenames belonging to 2 classes.\n",
      "Found 25 validated image filenames belonging to 2 classes.\n",
      "\n",
      "Data batches generated.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "batch_size = 160\n",
    "class_mode = \"categorical\"\n",
    "target_size=(224, 224)\n",
    "\n",
    "#this performs the data augmentation - \"get data function is here\"\n",
    "train_generator, validation_generator, test_generator, class_weights, steps_per_epoch, validation_steps = get_data(batch_size=batch_size, target_size=target_size, class_mode=class_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6f2a6",
   "metadata": {},
   "source": [
    "# 8. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58846f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "\n",
      "Timestamp: 2021-07-09 11:20:07\n",
      "\n",
      "\n",
      "Compliling Model ...\n",
      "\n",
      "Training Model ...\n",
      "\n",
      "WARNING:tensorflow:From /Users/sophiaty/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 86s 86s/step - loss: 0.5974 - sensitivity_at_specificity: 0.1842 - val_loss: 0.3932 - val_sensitivity_at_specificity: 0.3000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6824 - sensitivity_at_specificity: 0.2614 - val_loss: 0.3985 - val_sensitivity_at_specificity: 0.3000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4952 - sensitivity_at_specificity: 0.3261 - val_loss: 1.0841 - val_sensitivity_at_specificity: 0.3400\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3110 - sensitivity_at_specificity: 0.4043 - val_loss: 0.8432 - val_sensitivity_at_specificity: 0.4200\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2703 - sensitivity_at_specificity: 0.4664 - val_loss: 0.9310 - val_sensitivity_at_specificity: 0.4760\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.4318 - sensitivity_at_specificity: 0.5069 - val_loss: 0.6971 - val_sensitivity_at_specificity: 0.5133\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.5859 - sensitivity_at_specificity: 0.5118 - val_loss: 1.3486 - val_sensitivity_at_specificity: 0.4857\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0491 - sensitivity_at_specificity: 0.5722 - val_loss: 1.3779 - val_sensitivity_at_specificity: 0.5550\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1898 - sensitivity_at_specificity: 0.5662 - val_loss: 0.9767 - val_sensitivity_at_specificity: 0.5733\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2768 - sensitivity_at_specificity: 0.6189 - val_loss: 0.9019 - val_sensitivity_at_specificity: 0.6240\n",
      "\n",
      "Elapsed Time: 00:02:07\n",
      "Completed Model Trainning Timestamp: 2021-07-09 11:22:14\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(date_time(1))\n",
    "\n",
    "\n",
    "print(\"\\n\\nCompliling Model ...\\n\")\n",
    "learning_rate = 0.0001\n",
    "#optimizer = Adam(learning_rate)\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "##removed learning rate for now ST\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss, metrics=metrics) # look at loss and metrics section to \n",
    "verbose = 1\n",
    "epochs = 10\n",
    "\n",
    "print(\"Training Model ...\\n\")\n",
    "\n",
    "mod_class_weights = {0:class_weights[0], 1:class_weights[1]} #Modified the class weight to be a dict for training\n",
    "\n",
    "#modified to remove callbacks after verbose in model.fit(callbacks = callbacks)\n",
    "\n",
    "r = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    verbose=verbose,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight= mod_class_weights)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "\n",
    "print(\"\\nElapsed Time: \" + elapsed_time)\n",
    "# print(\"Elapsed Time/Epoch: \" + elapsed_time/epochs)\n",
    "print(\"Completed Model Trainning\", date_time(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b3fbe",
   "metadata": {},
   "source": [
    "# 9. Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5bb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(r.history['loss'], label='Loss')\n",
    "plt.plot(r.history['val_loss'], label='Val_Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(r.history['accuracy'], label='Accuracy')\n",
    "plt.plot(r.history['val_accuracy'], label='Val_Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Evolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98b12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5e269d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history=None, figure_directory=None):\n",
    "    xlabel = 'Epoch'\n",
    "    legends = ['Training', 'Validation']\n",
    "\n",
    "    ylim_pad = [0.01, 0.1]\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    # Plot training & validation Accuracy values\n",
    "\n",
    "    y1 = r.history['sensitivity_at_specificity']\n",
    "    y2 = r.history['val_sensitivity_at_specificity']\n",
    "\n",
    "    min_y = min(min(y1), min(y2))-ylim_pad[0]\n",
    "    max_y = max(max(y1), max(y2))+ylim_pad[0]\n",
    "\n",
    "\n",
    "    plt.subplot(121)\n",
    "\n",
    "    plt.plot(y1)\n",
    "    plt.plot(y2)\n",
    "\n",
    "    plt.title('Model Sensitivity at 95% Specificity\\n', fontsize=17)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel('Sensitivity', fontsize=15)\n",
    "    plt.ylim(min_y, max_y)\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "\n",
    "    y1 = r.history['loss']\n",
    "    y2 = r.history['val_loss']\n",
    "\n",
    "    min_y = min(min(y1), min(y2))-ylim_pad[1]\n",
    "    max_y = max(max(y1), max(y2))+ylim_pad[1]\n",
    "\n",
    "\n",
    "    plt.subplot(122)\n",
    "\n",
    "    plt.plot(y1)\n",
    "    plt.plot(y2)\n",
    "\n",
    "    plt.title('Model Loss\\n'+date_time(1), fontsize=17)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel('Loss', fontsize=15)\n",
    "    plt.ylim(min_y, max_y)\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.grid()\n",
    "    if figure_directory:\n",
    "        plt.savefig(figure_directory+\"/history\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd4a8361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_performance(history=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597e42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
